{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ec07c56-db77-40a0-a42f-696e54a0fba8",
   "metadata": {},
   "source": [
    "## Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ff82cf-965c-4ad9-a117-cfee300e9020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to install KAN library\n",
    "#pip install pykan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90102120-052a-4876-a5d1-e37f607c3ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from kan import *  \n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import moviepy.video.io.ImageSequenceClip\n",
    "\n",
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa1ea8e-5ea6-4cb9-adaa-3f603905d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset_v3.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73927894-a93b-4e33-91fd-175e30ff81ff",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2786291b-9ead-45bf-8e21-792d69460057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_set,batch_size=512):\n",
    "    dataset=data_set\n",
    "    dataset = shuffle(dataset, random_state=42)\n",
    "    data = dataset.drop('Label', axis=1).values\n",
    "    target = dataset['Label'].values\n",
    "\n",
    "    # Split dataset into train and test sets\n",
    "    train_data, test_data, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "    # scaler = StandardScaler()\n",
    "    # train_data = scaler.fit_transform(train_data)\n",
    "    # test_data = scaler.transform(test_data)\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    train_data = torch.tensor(train_data, dtype=torch.float32)\n",
    "    train_target = torch.tensor(train_target, dtype=torch.long)\n",
    "    test_data = torch.tensor(test_data, dtype=torch.float32)\n",
    "    test_target = torch.tensor(test_target, dtype=torch.long)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_data, train_target), batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_data, test_target), batch_size=batch_size, shuffle=false)\n",
    "\n",
    "    train_inputs = torch.empty(0, 4, device=device)\n",
    "    train_labels = torch.empty(0, dtype=torch.long, device=device)\n",
    "    test_inputs = torch.empty(0, 4, device=device)\n",
    "    test_labels = torch.empty(0, dtype=torch.long, device=device)\n",
    "\n",
    "\n",
    "    # Concatenate all data into a single tensor on the specified device\n",
    "    for data, labels in train_loader:\n",
    "        train_inputs = torch.cat((train_inputs, data.to(device)), dim=0)\n",
    "        train_labels = torch.cat((train_labels, labels.to(device)), dim=0)\n",
    "\n",
    "    for data, labels in test_loader:\n",
    "        test_inputs = torch.cat((test_inputs, data.to(device)), dim=0)\n",
    "        test_labels = torch.cat((test_labels, labels.to(device)), dim=0)\n",
    "\n",
    "\n",
    "    dataset = {}\n",
    "    dataset['train_input'] = train_inputs\n",
    "    dataset['test_input'] = test_inputs\n",
    "    dataset['train_label'] = train_labels\n",
    "    dataset['test_label'] = test_labels\n",
    "\n",
    "    \n",
    "\n",
    "    return dataset\n",
    "\n",
    "dataset = load_dataset(data,batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae740c2d-dfa5-4ab1-b6ba-ebc27da28512",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train data shape: {}\".format(dataset['train_input'].shape))\n",
    "print(\"Train target shape: {}\".format(dataset['train_label'].shape))\n",
    "print(\"Test data shape: {}\".format(dataset['test_input'].shape))\n",
    "print(\"Test target shape: {}\".format(dataset['test_label'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5563196d-572e-4b97-be64-43d9023e0e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_names = [\"Variance\", \"Skewness\", \"Kurtosis\", \"Entropy\"]\n",
    "column_names = [\"Var\", \"Skew\", \"Kurt\", \"Entp\"]\n",
    "target_names = [\"Real\", \"Fake\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a3a4cf-72a2-47fc-a7f7-b6545c0cdbb7",
   "metadata": {},
   "source": [
    "## Model Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5839c033-c201-493f-a0bc-1741cbbdeb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'video_img'\n",
    "\n",
    "model = KAN(width=[4, 4, 2], grid=3, k=3, seed=0, device=device)\n",
    "#k is for number of splines assigned per edge\n",
    "\n",
    "model(dataset['train_input'])\n",
    "model.plot(beta=100, scale=1, in_vars=column_names, out_vars=target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c551340e-1e99-4088-ab7c-7c23fd49e32d",
   "metadata": {},
   "source": [
    "## Metrics for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf42122-d445-4eb7-80ec-bb86bce4d039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_acc():\n",
    "    return torch.mean((torch.argmax(model(dataset['train_input']), dim=1) == dataset['train_label']).float())\n",
    "\n",
    "def test_acc():\n",
    "    return torch.mean((torch.argmax(model(dataset['test_input']), dim=1) == dataset['test_label']).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b76a31b-b230-434c-9321-d4e37e00425b",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19dff08-e005-4f58-afcb-85c762b53ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit(dataset, opt=\"Adam\", metrics=(train_acc, test_acc),\n",
    "                      loss_fn=torch.nn.CrossEntropyLoss(), steps=100, lamb=0.01, lamb_entropy=10., save_fig=True, img_folder=image_folder)\n",
    "model.plot(beta=100, scale=1, in_vars=column_names, out_vars=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12beefb4-5ab1-45d8-b2d9-a6e48be87121",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['train_acc'][-1], results['test_acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30241145-0c6b-46b3-9d1e-530ec47c0a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot(beta=100, scale=1,sample=True, in_vars=column_names, out_vars=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61d38f3-f884-4eb4-990c-cf37a09d9b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde9e3b5-4d91-4248-a4c8-bc9ecedb34ed",
   "metadata": {},
   "source": [
    "## Video Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa58b4-6ad5-4db0-b862-8cb4bba876aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name='fin_video'\n",
    "fps=5\n",
    "\n",
    "fps = fps\n",
    "files = os.listdir(image_folder)\n",
    "train_index = []\n",
    "for file in files:\n",
    "    if file[0].isdigit() and file.endswith('.jpg'):\n",
    "        train_index.append(int(file[:-4]))\n",
    "\n",
    "train_index = np.sort(train_index)\n",
    "\n",
    "image_files = [image_folder+'/'+str(train_index[index])+'.jpg' for index in train_index]\n",
    "\n",
    "clip = moviepy.video.io.ImageSequenceClip.ImageSequenceClip(image_files, fps=fps)\n",
    "clip.write_videofile(video_name+'.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8912790-4b2f-41b6-b00b-fe6e398e727d",
   "metadata": {},
   "source": [
    "## Pruning,assigning Symbols and optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4246a80-ca98-410c-9331-372ddbd4c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = model.prune()\n",
    "\n",
    "model1(dataset['train_input'])\n",
    "model1.plot(beta=1000,scale=1, in_vars=column_names, out_vars=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c301e20-f0ff-40de-bf3d-02af723d699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.rewind('0.1') \n",
    "#change value for rewinding to past models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4506da4a-91c7-4712-9263-c6c18475a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model1.parameters())\n",
    "trainable_params = sum(p.numel() for p in model1.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5a6b0e-700d-420b-b861-41007c64fb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "results =model1.fit(dataset, opt=\"Adam\", metrics=(train_acc, test_acc),\n",
    "                    loss_fn=torch.nn.CrossEntropyLoss(), steps=100, lamb=0.01, lamb_entropy=10., save_fig=True, img_folder=image_folder)\n",
    "results['train_acc'][-1], results['test_acc'][-1]\n",
    "model1.plot(scale=1, in_vars=column_names, out_vars=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283c58be-e372-4ca1-879b-dbf61f8292fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['train_acc'][-1], results['test_acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95477863-8bdd-4124-acdf-87b899d2e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = ['x','x^2','x^3','x^4','exp','log','sqrt','tanh','sin','tan','abs']\n",
    "model.auto_symbolic(lib=lib)\n",
    "model(dataset['train_input'])\n",
    "model.plot(beta=100,scale=1, in_vars=column_names, out_vars=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590fb005-b0e0-4092-a9c4-f1dbac4d906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c1feee-07d1-4812-a869-19095d15ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results =model.fit(dataset, opt=\"Adam\", metrics=(train_acc, test_acc),\n",
    "                    loss_fn=torch.nn.CrossEntropyLoss(), steps=50, lamb=0.01, lamb_entropy=10., save_fig=True, img_folder=image_folder)\n",
    "results['train_acc'][-1], results['test_acc'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a814a69-960a-4e27-8166-022085c62a06",
   "metadata": {},
   "source": [
    "## sample comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6524d9a6-913b-4c57-ac78-13c14d06ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 6)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(6, 6)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(6, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to the specified device\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to the specified device\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8ab53b-b04c-4c6f-8c01-ae6ed223afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_set,batch_size=512):\n",
    "    dataset=data_set\n",
    "    dataset = shuffle(dataset, random_state=42)\n",
    "    data = dataset.drop('Label', axis=1).values\n",
    "    target = dataset['Label'].values\n",
    "\n",
    "    # Split dataset into train and test sets\n",
    "    train_data, test_data, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "    # scaler = StandardScaler()\n",
    "    # train_data = scaler.fit_transform(train_data)\n",
    "    # test_data = scaler.transform(test_data)\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    train_data = torch.tensor(train_data, dtype=torch.float32)\n",
    "    train_target = torch.tensor(train_target, dtype=torch.long)\n",
    "    test_data = torch.tensor(test_data, dtype=torch.float32)\n",
    "    test_target = torch.tensor(test_target, dtype=torch.long)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_data, train_target), batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_data, test_target), batch_size=batch_size, shuffle=false)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = load_dataset(data,batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c090e067-83d7-4f42-8412-7fe9024089d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef01417-7fe6-4707-94f9-fd668d82fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b977176d-5560-4f00-b6a1-68c8c4e70e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758db16b-aaf1-4864-b031-299428a6fce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kzml",
   "language": "python",
   "name": "kzml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
